<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-CN">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/remove.io/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/remove.io/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/remove.io/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/img/wico.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/img/wico.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/img/wico.png?v=5.1.4">


  <link rel="mask-icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/img/wico.png?v=5.1.4" color="#222">





  <meta name="keywords" content="categories-java,Kafka基本架构及原理">





  <link rel="alternate" href="/remove.io/atom.xml" title="辣椒の酱" type="application/atom+xml">






<meta name="description" content="一、为什么需要消息系统1.解耦：    允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。2.冗余：    消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。3.扩展性：    因">
<meta name="keywords" content="categories-java,Kafka基本架构及原理">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka基本架构及原理">
<meta property="og:url" content="https://removeif.github.io/design-architecture/Kafka基本架构及原理.html">
<meta property="og:site_name" content="辣椒の酱">
<meta property="og:description" content="一、为什么需要消息系统1.解耦：    允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。2.冗余：    消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。3.扩展性：    因">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112014.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112250.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112612.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112822.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112925.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113026.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113536.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113951.png">
<meta property="og:updated_time" content="2020-02-06T03:27:44.577Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Kafka基本架构及原理">
<meta name="twitter:description" content="一、为什么需要消息系统1.解耦：    允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。2.冗余：    消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。3.扩展性：    因">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112014.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/remove.io/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>
<script data-ad-client="ca-pub-6343805421927634" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata|Itim|Lobster.css">





  <link rel="canonical" href="https://removeif.github.io/design-architecture/Kafka基本架构及原理.html">





  <title>Kafka基本架构及原理 | 辣椒の酱</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/remove.io/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">辣椒の酱</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">尚未执佩剑，转眼即江湖</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/remove.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/remove.io/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/remove.io/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/remove.io/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-message">
          <a href="https://removeif.github.io/message/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            message
          </a>
        </li>
      
        
        <li class="menu-item menu-item-master">
          <a href="https://removeif.github.io/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            master
          </a>
        </li>
      

      
        <div class="g-ads-y">
            <br>
            <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
            <ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-6343805421927634" data-ad-slot="6639418948" data-ad-format="auto" data-full-width-responsive="true"></ins>
            <script>(adsbygoogle = window.adsbygoogle || []).push({});</script>
        </div>
    </ul>
  

  

</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://removeif.github.io/remove.io/design-architecture/Kafka基本架构及原理.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="辣椒の酱">
      <meta itemprop="description" content>
      <meta itemprop="image" content="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/images/tuzi.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="辣椒の酱">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">Kafka基本架构及原理</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-02-02T11:47:53+08:00">
                2020-02-02
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/remove.io/categories/架构/" itemprop="url" rel="index">
                    <span itemprop="name">架构</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/remove.io/categories/架构/Kafka/" itemprop="url" rel="index">
                    <span itemprop="name">Kafka</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="一、为什么需要消息系统"><a href="#一、为什么需要消息系统" class="headerlink" title="一、为什么需要消息系统"></a>一、为什么需要消息系统</h3><p>1.解耦：<br>    允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。<br>2.冗余：<br>    消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。<br>3.扩展性：<br>    因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。<a id="more"></a><br>4.灵活性 &amp; 峰值处理能力：<br>    在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见。如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。<br>5.可恢复性：<br>    系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。<br>6.顺序保证：<br>    在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。（Kafka 保证一个 Partition 内的消息的有序性）<br>7.缓冲：<br>    有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。<br>8.异步通信：<br>    很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。</p>
<h3 id="二、kafka-架构"><a href="#二、kafka-架构" class="headerlink" title="二、kafka 架构"></a>二、kafka 架构</h3><h4 id="拓扑结构"><a href="#拓扑结构" class="headerlink" title="拓扑结构"></a>拓扑结构</h4><p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112014.png" alt></p>
<p> 相关名词解释:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">1.producer：</span><br><span class="line">　　消息生产者，发布消息到 kafka 集群的终端或服务。</span><br><span class="line">2.broker：</span><br><span class="line">　　kafka 集群中包含的服务器。</span><br><span class="line">3.topic：</span><br><span class="line">　　每条发布到 kafka 集群的消息属于的类别，即 kafka 是面向 topic 的。</span><br><span class="line">4.partition：</span><br><span class="line">　　partition 是物理上的概念，每个 topic 包含一个或多个 partition。kafka 分配的单位是 partition。</span><br><span class="line">5.consumer：</span><br><span class="line">　　从 kafka 集群中消费消息的终端或服务。</span><br><span class="line">6.Consumer group：</span><br><span class="line">　　high-level consumer API 中，每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 中的一个 Consumer 消费，但可以被多个 consumer group 消费。</span><br><span class="line">7.replica：</span><br><span class="line">　　partition 的副本，保障 partition 的高可用。</span><br><span class="line">8.leader：</span><br><span class="line">　　replica 中的一个角色， producer 和 consumer 只跟 leader 交互。</span><br><span class="line">9.follower：</span><br><span class="line">　　replica 中的一个角色，从 leader 中复制数据。</span><br><span class="line">10.controller：</span><br><span class="line">　　kafka 集群中的其中一个服务器，用来进行 leader election 以及 各种 failover。</span><br><span class="line">12.zookeeper：</span><br><span class="line">　　kafka 通过 zookeeper 来存储集群的 meta 信息。</span><br></pre></td></tr></table></figure>

<h4 id="zookeeper-节点"><a href="#zookeeper-节点" class="headerlink" title="zookeeper 节点"></a>zookeeper 节点</h4><p>kafka 在 zookeeper 中的存储结构如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112250.png" alt></p>
<h3 id="三、producer-发布消息"><a href="#三、producer-发布消息" class="headerlink" title="三、producer 发布消息"></a>三、producer 发布消息</h3><h4 id="写入方式"><a href="#写入方式" class="headerlink" title="写入方式"></a>写入方式</h4><p>producer 采用 push 模式将消息发布到 broker，每条消息都被 append 到 patition 中，属于顺序写磁盘（顺序写磁盘效率比随机写内存要高，保障 kafka 吞吐率）。</p>
<h4 id="消息路由"><a href="#消息路由" class="headerlink" title="消息路由"></a>消息路由</h4><p>producer 发送消息到 broker 时，会根据分区算法选择将其存储到哪一个 partition。其路由机制为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 指定了 patition，则直接使用；</span><br><span class="line">2. 未指定 patition 但指定 key，通过对 key 的 value 进行hash 选出一个 patition</span><br><span class="line">3. patition 和 key 都未指定，使用轮询选出一个 patition。</span><br></pre></td></tr></table></figure>

<p>附上 java 客户端分区源码，一目了然：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建消息实例</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ProducerRecord</span><span class="params">(String topic, Integer partition, Long timestamp, K key, V value)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">if</span> (topic == <span class="keyword">null</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Topic cannot be null"</span>);</span><br><span class="line">     <span class="keyword">if</span> (timestamp != <span class="keyword">null</span> &amp;&amp; timestamp &lt; <span class="number">0</span>)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid timestamp "</span> + timestamp);</span><br><span class="line">     <span class="keyword">this</span>.topic = topic;</span><br><span class="line">     <span class="keyword">this</span>.partition = partition;</span><br><span class="line">     <span class="keyword">this</span>.key = key;</span><br><span class="line">     <span class="keyword">this</span>.value = value;</span><br><span class="line">     <span class="keyword">this</span>.timestamp = timestamp;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//计算 patition，如果指定了 patition 则直接使用，否则使用 key 计算</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(ProducerRecord&lt;K, V&gt; record, <span class="keyword">byte</span>[] serializedKey , <span class="keyword">byte</span>[] serializedValue, Cluster cluster)</span> </span>&#123;</span><br><span class="line">     Integer partition = record.partition();</span><br><span class="line">     <span class="keyword">if</span> (partition != <span class="keyword">null</span>) &#123;</span><br><span class="line">          List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(record.topic());</span><br><span class="line">          <span class="keyword">int</span> lastPartition = partitions.size() - <span class="number">1</span>;</span><br><span class="line">          <span class="keyword">if</span> (partition &lt; <span class="number">0</span> || partition &gt; lastPartition) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(<span class="string">"Invalid partition given with record: %d is not in the range [0...%d]."</span>, partition, lastPartition));</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">return</span> partition;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> <span class="keyword">this</span>.partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用 key 选取 patition</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object key, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">     List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);</span><br><span class="line">     <span class="keyword">int</span> numPartitions = partitions.size();</span><br><span class="line">     <span class="keyword">if</span> (keyBytes == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">int</span> nextValue = counter.getAndIncrement();</span><br><span class="line">          List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);</span><br><span class="line">          <span class="keyword">if</span> (availablePartitions.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">               <span class="keyword">int</span> part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();</span><br><span class="line">               <span class="keyword">return</span> availablePartitions.get(part).partition();</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">               <span class="keyword">return</span> DefaultPartitioner.toPositive(nextValue) % numPartitions;</span><br><span class="line">          &#125;</span><br><span class="line">     &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">//对 keyBytes 进行 hash 选出一个 patition</span></span><br><span class="line">          <span class="keyword">return</span> DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="写入流程"><a href="#写入流程" class="headerlink" title="写入流程"></a>写入流程</h4><p>producer 写入消息序列图:</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112612.png" alt></p>
<p>流程说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. producer 先从 zookeeper 的 &quot;/brokers/.../state&quot; 节点找到该 partition 的 leader</span><br><span class="line">2. producer 将消息发送给该 leader</span><br><span class="line">3. leader 将消息写入本地 log</span><br><span class="line">4. followers 从 leader pull 消息，写入本地 log 后 leader 发送 ACK</span><br><span class="line">5. leader 收到所有 ISR 中的 replica 的 ACK 后，增加 HW（high watermark，最后 commit 的 offset） 并向 producer 发送 ACK</span><br></pre></td></tr></table></figure>

<h4 id="producer-delivery-guarantee"><a href="#producer-delivery-guarantee" class="headerlink" title="producer delivery guarantee"></a>producer delivery guarantee</h4><p>一般情况下存在三种情况：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. At most once 消息可能会丢，但绝不会重复传输</span><br><span class="line">2. At least one 消息绝不会丢，但可能会重复传输</span><br><span class="line">3. Exactly once 每条消息肯定会被传输一次且仅传输一次</span><br></pre></td></tr></table></figure>

<p>当 producer 向 broker 发送消息时，一旦这条消息被 commit，由于 replication 的存在，它就不会丢。但是如果 producer 发送数据给 broker 后，遇到网络问题而造成通信中断，那 Producer 就无法判断该条消息是否已经 commit。虽然 Kafka 无法确定网络故障期间发生了什么，但是 producer 可以生成一种类似于主键的东西，发生故障时幂等性的重试多次，这样就做到了 Exactly once，但目前还并未实现。所以目前默认情况下一条消息从 producer 到 broker 是确保了 At least once，可通过设置 producer 异步发送实现At most once。</p>
<h3 id="四、broker-保存消息"><a href="#四、broker-保存消息" class="headerlink" title="四、broker 保存消息"></a>四、broker 保存消息</h3><h4 id="存储方式"><a href="#存储方式" class="headerlink" title="存储方式"></a>存储方式</h4><p>物理上把 topic 分成一个或多个 patition（对应 server.properties 中的 num.partitions=3 配置），每个 patition 物理上对应一个文件夹（该文件夹存储该 patition 的所有消息和索引文件），如下：</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112822.png" alt></p>
<h4 id="存储策略"><a href="#存储策略" class="headerlink" title="存储策略"></a>存储策略</h4><p>无论消息是否被消费，kafka 都会保留所有消息。有两种策略可以删除旧数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 基于时间：log.retention.hours=168</span><br><span class="line">2. 基于大小：log.retention.bytes=1073741824</span><br></pre></td></tr></table></figure>

<p>需要注意的是，因为Kafka读取特定消息的时间复杂度为O(1)，即与文件大小无关，所以这里删除过期文件与提高 Kafka 性能无关。</p>
<h4 id="topic-创建与删除"><a href="#topic-创建与删除" class="headerlink" title="topic 创建与删除"></a>topic 创建与删除</h4><h5 id="创建-topic"><a href="#创建-topic" class="headerlink" title="创建 topic"></a>创建 topic</h5><p>创建 topic 的序列图</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202112925.png" alt></p>
<p>流程说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. controller 在 ZooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被创建，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。</span><br><span class="line">2. controller从 /brokers/ids 读取当前所有可用的 broker 列表，对于 set_p 中的每一个 partition：</span><br><span class="line">   2.1 从分配给该 partition 的所有 replica（称为AR）中任选一个可用的 broker 作为新的 leader，并将AR设置为新的 ISR</span><br><span class="line">   2.2 将新的 leader 和 ISR 写入 /brokers/topics/[topic]/partitions/[partition]/state</span><br><span class="line">3. controller 通过 RPC 向相关的 broker 发送 LeaderAndISRRequest。</span><br></pre></td></tr></table></figure>

<h5 id="删除-topic"><a href="#删除-topic" class="headerlink" title="删除 topic"></a>删除 topic</h5><p>删除 topic 的序列图</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113026.png" alt></p>
<p>流程说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. controller 在 zooKeeper 的 /brokers/topics 节点上注册 watcher，当 topic 被删除，则 controller 会通过 watch 得到该 topic 的 partition/replica 分配。</span><br><span class="line">2. 若 delete.topic.enable=false，结束；否则 controller 注册在 /admin/delete_topics 上的 watch 被 fire，controller 通过回调向对应的 broker 发送 StopReplicaRequest。</span><br></pre></td></tr></table></figure>

<h3 id="五、kafka-HA"><a href="#五、kafka-HA" class="headerlink" title="五、kafka HA"></a>五、kafka HA</h3><h4 id="replication"><a href="#replication" class="headerlink" title="replication"></a>replication</h4><p>如图.1所示，同一个 partition 可能会有多个 replica（对应 server.properties 配置中的 default.replication.factor=N）。没有 replica 的情况下，一旦 broker 宕机，其上所有 patition 的数据都不可被消费，同时 producer 也不能再将数据存于其上的 patition。引入replication 之后，同一个 partition 可能会有多个 replica，而这时需要在这些 replica 之间选出一个 leader，producer 和 consumer 只与这个 leader 交互，其它 replica 作为 follower 从 leader 中复制数据。</p>
<p>Kafka 分配 Replica 的算法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 将所有 broker（假设共 n 个 broker）和待分配的 partition 排序</span><br><span class="line">2. 将第 i 个 partition 分配到第（i mod n）个 broker 上</span><br><span class="line">3. 将第 i 个 partition 的第 j 个 replica 分配到第（(i + j) mode n）个 broker上</span><br></pre></td></tr></table></figure>

<h4 id="leader-failover"><a href="#leader-failover" class="headerlink" title="leader failover"></a>leader failover</h4><p>当 partition 对应的 leader 宕机时，需要从 follower 中选举出新 leader。在选举新leader时，一个基本的原则是，新的 leader 必须拥有旧 leader commit 过的所有消息。</p>
<p>kafka 在 zookeeper 中（/brokers/…/state）动态维护了一个 ISR（in-sync replicas），由3.3节的写入流程可知 ISR 里面的所有 replica 都跟上了 leader，只有 ISR 里面的成员才能选为 leader。对于 f+1 个 replica，一个 partition 可以在容忍 f 个 replica 失效的情况下保证消息不丢失。</p>
<p>当所有 replica 都不工作时，有两种可行的方案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 等待 ISR 中的任一个 replica 活过来，并选它作为 leader。可保障数据不丢失，但时间可能相对较长。</span><br><span class="line">2. 选择第一个活过来的 replica（不一定是 ISR 成员）作为 leader。无法保障数据不丢失，但相对不可用时间较短。</span><br></pre></td></tr></table></figure>

<p>kafka 0.8.* 使用第二种方式。</p>
<p>kafka 通过 Controller 来选举 leader，流程请参考5.3节。</p>
<h4 id="broker-failover"><a href="#broker-failover" class="headerlink" title="broker failover"></a>broker failover</h4><p>kafka broker failover 序列图如下所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113536.png" alt></p>
<p>流程说明：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. controller 在 zookeeper 的 /brokers/ids/[brokerId] 节点注册 Watcher，当 broker 宕机时 zookeeper 会 fire watch</span><br><span class="line">2. controller 从 /brokers/ids 节点读取可用broker</span><br><span class="line">3. controller决定set_p，该集合包含宕机 broker 上的所有 partition</span><br><span class="line">4. 对 set_p 中的每一个 partition</span><br><span class="line">    4.1 从/brokers/topics/[topic]/partitions/[partition]/state 节点读取 ISR</span><br><span class="line">    4.2 决定新 leader（如4.3节所描述）</span><br><span class="line">    4.3 将新 leader、ISR、controller_epoch 和 leader_epoch 等信息写入 state 节点</span><br><span class="line">5. 通过 RPC 向相关 broker 发送 leaderAndISRRequest 命令</span><br></pre></td></tr></table></figure>

<h4 id="controller-failover"><a href="#controller-failover" class="headerlink" title="controller failover"></a>controller failover</h4><p>当 controller 宕机时会触发 controller failover。每个 broker 都会在 zookeeper 的 “/controller” 节点注册 watcher，当 controller 宕机时 zookeeper 中的临时节点消失，所有存活的 broker 收到 fire 的通知，每个 broker 都尝试创建新的 controller path，只有一个竞选成功并当选为 controller。</p>
<p>当新的 controller 当选时，会触发 KafkaController.onControllerFailover 方法，在该方法中完成如下操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> 1. 读取并增加 Controller Epoch。</span><br><span class="line"> 2. 在 reassignedPartitions Patch(/admin/reassign_partitions) 上注册 watcher。</span><br><span class="line"> 3. 在 preferredReplicaElection Path(/admin/preferred_replica_election) 上注册 watcher。</span><br><span class="line"> 4. 通过 partitionStateMachine 在 broker Topics Patch(/brokers/topics) 上注册 watcher。</span><br><span class="line"> 5. 若 delete.topic.enable=true（默认值是 false），则 partitionStateMachine 在 Delete Topic Patch(/admin/delete_topics) 上注册 watcher。</span><br><span class="line"> 6. 通过 replicaStateMachine在 Broker Ids Patch(/brokers/ids)上注册Watch。</span><br><span class="line"> 7. 初始化 ControllerContext 对象，设置当前所有 topic，“活”着的 broker 列表，所有 partition 的 leader 及 ISR等。</span><br><span class="line"> 8. 启动 replicaStateMachine 和 partitionStateMachine。</span><br><span class="line"> 9. 将 brokerState 状态设置为 RunningAsController。</span><br><span class="line">10. 将每个 partition 的 Leadership 信息发送给所有“活”着的 broker。</span><br><span class="line">11. 若 auto.leader.rebalance.enable=true（默认值是true），则启动 partition-rebalance 线程。</span><br><span class="line">12. 若 delete.topic.enable=true 且Delete Topic Patch(/admin/delete_topics)中有值，则删除相应的Topic。</span><br></pre></td></tr></table></figure>

<h3 id="六、consumer-消费消息"><a href="#六、consumer-消费消息" class="headerlink" title="六、consumer 消费消息"></a>六、consumer 消费消息</h3><h4 id="consumer-API"><a href="#consumer-API" class="headerlink" title="consumer API"></a>consumer API</h4><p>kafka 提供了两套 consumer API：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. The high-level Consumer API</span><br><span class="line">2. The SimpleConsumer API</span><br></pre></td></tr></table></figure>

<p>其中 high-level consumer API 提供了一个从 kafka 消费数据的高层抽象，而 SimpleConsumer API 则需要开发人员更多地关注细节。</p>
<h5 id="The-high-level-consumer-API"><a href="#The-high-level-consumer-API" class="headerlink" title="The high-level consumer API"></a>The high-level consumer API</h5><p>high-level consumer API 提供了 consumer group 的语义，一个消息只能被 group 内的一个 consumer 所消费，且 consumer 消费消息时不关注 offset，最后一个 offset 由 zookeeper 保存。</p>
<p>使用 high-level consumer API 可以是多线程的应用，应当注意：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 如果消费线程大于 patition 数量，则有些线程将收不到消息</span><br><span class="line">2. 如果 patition 数量大于线程数，则有些线程多收到多个 patition 的消息</span><br><span class="line">3. 如果一个线程消费多个 patition，则无法保证你收到的消息的顺序，而一个 patition 内的消息是有序的</span><br></pre></td></tr></table></figure>

<h5 id="The-SimpleConsumer-API"><a href="#The-SimpleConsumer-API" class="headerlink" title="The SimpleConsumer API"></a>The SimpleConsumer API</h5><p>如果你想要对 patition 有更多的控制权，那就应该使用 SimpleConsumer API，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 多次读取一个消息</span><br><span class="line">2. 只消费一个 patition 中的部分消息</span><br><span class="line">3. 使用事务来保证一个消息仅被消费一次</span><br></pre></td></tr></table></figure>

<p>但是使用此 API 时，partition、offset、broker、leader 等对你不再透明，需要自己去管理。你需要做大量的额外工作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 必须在应用程序中跟踪 offset，从而确定下一条应该消费哪条消息</span><br><span class="line">2. 应用程序需要通过程序获知每个 Partition 的 leader 是谁</span><br><span class="line">3. 需要处理 leader 的变更</span><br></pre></td></tr></table></figure>

<p>使用 SimpleConsumer API 的一般流程如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 查找到一个“活着”的 broker，并且找出每个 partition 的 leader</span><br><span class="line">2. 找出每个 partition 的 follower</span><br><span class="line">3. 定义好请求，该请求应该能描述应用程序需要哪些数据</span><br><span class="line">4. fetch 数据</span><br><span class="line">5. 识别 leader 的变化，并对之作出必要的响应</span><br></pre></td></tr></table></figure>

<blockquote>
<p>以下针对 high-level Consumer API 进行说明。</p>
</blockquote>
<h4 id="consumer-group"><a href="#consumer-group" class="headerlink" title="consumer group"></a>consumer group</h4><p>如 2.2 节所说， kafka 的分配单位是 patition。每个 consumer 都属于一个 group，一个 partition 只能被同一个 group 内的一个 consumer 所消费（也就保障了一个消息只能被 group 内的一个 consuemr 所消费），但是多个 group 可以同时消费这个 partition。</p>
<p>kafka 的设计目标之一就是同时实现离线处理和实时处理，根据这一特性，可以使用 spark/Storm 这些实时处理系统对消息在线处理，同时使用 Hadoop 批处理系统进行离线处理，还可以将数据备份到另一个数据中心，只需要保证这三者属于不同的 consumer group。如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/removeif/blog_image/img/2020/20200202113951.png" alt></p>
<h4 id="消费方式"><a href="#消费方式" class="headerlink" title="消费方式"></a>消费方式</h4><p>consumer 采用 pull 模式从 broker 中读取数据。</p>
<p>push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。</p>
<p>对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。</p>
<h4 id="consumer-delivery-guarantee"><a href="#consumer-delivery-guarantee" class="headerlink" title="consumer delivery guarantee"></a>consumer delivery guarantee</h4><p>如果将 consumer 设置为 autocommit，consumer 一旦读到数据立即自动 commit。如果只讨论这一读取消息的过程，那 Kafka 确保了 Exactly once。</p>
<p>但实际使用中应用程序并非在 consumer 读取完数据就结束了，而是要进行进一步处理，而数据处理与 commit 的顺序在很大程度上决定了consumer delivery guarantee：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.读完消息先 commit 再处理消息。</span><br><span class="line">    这种模式下，如果 consumer 在 commit 后还没来得及处理消息就 crash 了，下次重新开始工作后就无法读到刚刚已提交而未处理的消息，这就对应于 At most once</span><br><span class="line">2.读完消息先处理再 commit。</span><br><span class="line">    这种模式下，如果在处理完消息之后 commit 之前 consumer crash 了，下次重新开始工作时还会处理刚刚未 commit 的消息，实际上该消息已经被处理过了。这就对应于 At least once。</span><br><span class="line">3.如果一定要做到 Exactly once，就需要协调 offset 和实际操作的输出。</span><br><span class="line">    精典的做法是引入两阶段提交。如果能让 offset 和操作输入存在同一个地方，会更简洁和通用。这种方式可能更好，因为许多输出系统可能不支持两阶段提交。比如，consumer 拿到数据后可能把数据放到 HDFS，如果把最新的 offset 和数据本身一起写到 HDFS，那就可以保证数据的输出和 offset 的更新要么都完成，要么都不完成，间接实现 Exactly once。（目前就 high-level API而言，offset 是存于Zookeeper 中的，无法存于HDFS，而SimpleConsuemr API的 offset 是由自己去维护的，可以将之存于 HDFS 中）</span><br></pre></td></tr></table></figure>

<p>总之，Kafka 默认保证 At least once，并且允许通过设置 producer 异步提交来实现 At most once（见文章《kafka consumer防止数据丢失》）。而 Exactly once 要求与外部存储系统协作，幸运的是 kafka 提供的 offset 可以非常直接非常容易得使用这种方式。</p>
<p>更多关于 kafka 传输语义的信息请参考《Message Delivery Semantics》。</p>
<h4 id="consumer-rebalance"><a href="#consumer-rebalance" class="headerlink" title="consumer rebalance"></a>consumer rebalance</h4><p>当有 consumer 加入或退出、以及 partition 的改变（如 broker 加入或退出）时会触发 rebalance。consumer rebalance算法如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. 将目标 topic 下的所有 partirtion 排序，存于PT</span><br><span class="line">2. 对某 consumer group 下所有 consumer 排序，存于 CG，第 i 个consumer 记为 Ci</span><br><span class="line">3. N=size(PT)/size(CG)，向上取整</span><br><span class="line">4. 解除 Ci 对原来分配的 partition 的消费权（i从0开始）</span><br><span class="line">5. 将第i*N到（i+1）*N-1个 partition 分配给 Ci</span><br></pre></td></tr></table></figure>

<p>在 0.8.*版本，每个 consumer 都只负责调整自己所消费的 partition，为了保证整个consumer group 的一致性，当一个 consumer 触发了 rebalance 时，该 consumer group 内的其它所有其它 consumer 也应该同时触发 rebalance。这会导致以下几个问题：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.Herd effect</span><br><span class="line">　　任何 broker 或者 consumer 的增减都会触发所有的 consumer 的 rebalance</span><br><span class="line">2.Split Brain</span><br><span class="line">　　每个 consumer 分别单独通过 zookeeper 判断哪些 broker 和 consumer 宕机了，那么不同 consumer 在同一时刻从 zookeeper 看到的 view 就可能不一样，这是由 zookeeper 的特性决定的，这就会造成不正确的 reblance 尝试。</span><br><span class="line">3. 调整结果不可控</span><br><span class="line">　　所有的 consumer 都并不知道其它 consumer 的 rebalance 是否成功，这可能会导致 kafka 工作在一个不正确的状态。</span><br></pre></td></tr></table></figure>

<p>基于以上问题，kafka 设计者考虑在0.9.*版本开始使用中心 coordinator 来控制 consumer rebalance，然后又从简便性和验证要求两方面考虑，计划在 consumer 客户端实现分配方案。（见文章《Kafka Detailed Consumer Coordinator Design》和《Kafka Client-side Assignment Proposal》），此处不再赘述。</p>
<h3 id="七、注意事项"><a href="#七、注意事项" class="headerlink" title="七、注意事项"></a>七、注意事项</h3><h4 id="producer-无法发送消息的问题"><a href="#producer-无法发送消息的问题" class="headerlink" title="producer 无法发送消息的问题"></a>producer 无法发送消息的问题</h4><p>最开始在本机搭建了kafka伪集群，本地 producer 客户端成功发布消息至 broker。随后在服务器上搭建了 kafka 集群，在本机连接该集群，producer 却无法发布消息到 broker（奇怪也没有抛错）。最开始怀疑是 iptables 没开放，于是开放端口，结果还不行（又开始是代码问题、版本问题等等，倒腾了很久）。最后没办法，一项一项查看 server.properties 配置，发现以下两个配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># The address the socket server listens on. It will get the value returned from </span><br><span class="line"># java.net.InetAddress.getCanonicalHostName() if not configured.</span><br><span class="line">#   FORMAT:</span><br><span class="line">#     listeners = security_protocol://host_name:port</span><br><span class="line">#   EXAMPLE:</span><br><span class="line">#     listeners = PLAINTEXT://your.host.name:9092</span><br><span class="line">listeners=PLAINTEXT://:9092</span><br><span class="line"></span><br><span class="line"># Hostname and port the broker will advertise to producers and consumers. If not set, </span><br><span class="line"># it uses the value for &quot;listeners&quot; if configured. Otherwise, it will use the value</span><br><span class="line"># returned from java.net.InetAddress.getCanonicalHostName().</span><br><span class="line"># advertised.listeners=PLAINTEXT://your.host.name:9092</span><br></pre></td></tr></table></figure>

<p>以上说的就是 advertised.listeners 是 broker 给 producer 和 consumer 连接使用的，如果没有设置，就使用 listeners，而如果 host_name 没有设置的话，就使用 java.net.InetAddress.getCanonicalHostName() 方法返回的主机名。</p>
<p>修改方法：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. listeners=PLAINTEXT://121.10.26.XXX:9092</span><br><span class="line">2. advertised.listeners=PLAINTEXT://121.10.26.XXX:9092</span><br></pre></td></tr></table></figure>

<p>修改后重启服务，正常工作。关于更多 kafka 配置说明，见文章《<a href="http://blog.csdn.net/louisliaoxh/article/details/51516084" target="_blank" rel="noopener">Kafka学习整理三(borker(0.9.0及0.10.0)配置)</a>》。</p>
<h3 id="八、参考相关文章列表"><a href="#八、参考相关文章列表" class="headerlink" title="八、参考相关文章列表"></a>八、参考相关文章列表</h3><blockquote>
<ol>
<li><p>《<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-1/" target="_blank" rel="noopener">Kafka剖析（一）：Kafka背景及架构介绍</a>》</p>
</li>
<li><p>《<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-2/" target="_blank" rel="noopener">Kafka设计解析（二）：Kafka High Availability （上）</a>》</p>
</li>
<li><p>《<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-3/" target="_blank" rel="noopener">Kafka设计解析（二）：Kafka High Availability （下）</a>》</p>
</li>
<li><p>《<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-4/" target="_blank" rel="noopener">Kafka设计解析（四）：Kafka Consumer解析</a>》</p>
</li>
<li><p>《<a href="http://www.infoq.com/cn/articles/kafka-analysis-part-5" target="_blank" rel="noopener">Kafka设计解析（五）：Kafka Benchmark</a>》</p>
</li>
<li><p>《<a href="http://blog.csdn.net/louisliaoxh/article/details/51516084" target="_blank" rel="noopener">Kafka学习整理三(borker(0.9.0及0.10.0)配置)</a>》</p>
</li>
<li><p>《<a href="https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Group+Example" target="_blank" rel="noopener">Using the High Level Consumer</a>》</p>
</li>
<li><p>《<a href="https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+SimpleConsumer+Example" target="_blank" rel="noopener">Using SimpleConsumer</a>》</p>
</li>
<li><p>《<a href="https://cwiki.apache.org/confluence/display/KAFKA/Consumer+Client+Re-Design" target="_blank" rel="noopener">Consumer Client Re-Design</a>》</p>
</li>
<li><p>《<a href="http://kafka.apache.org/documentation.html#semantics" target="_blank" rel="noopener">Message Delivery Semantics</a>》</p>
</li>
<li><p>《<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Detailed+Consumer+Coordinator+Design#KafkaDetailedConsumerCoordinatorDesign-WARN:Thisisanobsoletedesign.Thedesignthat'simplementedinKafka0.9.0isdescribedinthiswiki." target="_blank" rel="noopener">Kafka Detailed Consumer Coordinator Design</a>》</p>
</li>
<li><p>《<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Client-side+Assignment+Proposal" target="_blank" rel="noopener">Kafka Client-side Assignment Proposal</a>》</p>
</li>
<li><p>《<a href="http://www.infoq.com/cn/articles/technology-comparison-of-kafka-and-distributedlog?utm_campaign=rightbar_v2&utm_source=infoq&utm_medium=articles_link&utm_content=link_text" target="_blank" rel="noopener">Kafka和DistributedLog技术对比</a>》</p>
</li>
<li><p>《<a href="http://orchome.com/6" target="_blank" rel="noopener">kafka安装和启动</a>》</p>
</li>
<li><p>《<a href="http://kane-xie.iteye.com/blog/2225085" target="_blank" rel="noopener">kafka consumer防止数据丢失</a>》</p>
</li>
</ol>
</blockquote>
<p>参考文章:<br><a href="https://www.cnblogs.com/cyfonly/p/5954614.html" target="_blank" rel="noopener">参考链接</a></p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>Post author:</strong>
    辣椒の酱
  </li>
  <li class="post-copyright-link">
    <strong>Post link:</strong>
    <a href="https://removeif.github.io/design-architecture/Kafka基本架构及原理.html" title="Kafka基本架构及原理">https://removeif.github.io/design-architecture/Kafka基本架构及原理.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>Copyright Notice: </strong>
    All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 4.0</a> unless stating additionally.
  </li>
  <li class="post-copyright-license">
      <strong>文章评论：</strong>
      <a href="https://removeif.github.io/design-architecture/Kafka基本架构及原理.html#comment-container">点击评论</a>
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/remove.io/tags/Kafka/" rel="tag"># Kafka</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/remove.io/develop/Git-rebase-用法示例小结.html" rel="next" title="Git-rebase-用法示例小结">
                <i class="fa fa-chevron-left"></i> Git-rebase-用法示例小结
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/remove.io/design-architecture/秒杀系统如何支撑百万QPS.html" rel="prev" title="秒杀系统如何支撑百万QPS">
                秒杀系统如何支撑百万QPS <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="https://cdn.jsdelivr.net/gh/removeif/removeif.github.io@master/images/tuzi.jpg" alt="辣椒の酱">
            
              <p class="site-author-name" itemprop="name">辣椒の酱</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/remove.io/archives/">
              
                  <span class="site-state-item-count">117</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/remove.io/categories/index.html">
                  <span class="site-state-item-count">42</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/remove.io/tags/index.html">
                  <span class="site-state-item-count">84</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/remove.io/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、为什么需要消息系统"><span class="nav-number">1.</span> <span class="nav-text">一、为什么需要消息系统</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、kafka-架构"><span class="nav-number">2.</span> <span class="nav-text">二、kafka 架构</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#拓扑结构"><span class="nav-number">2.1.</span> <span class="nav-text">拓扑结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#zookeeper-节点"><span class="nav-number">2.2.</span> <span class="nav-text">zookeeper 节点</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三、producer-发布消息"><span class="nav-number">3.</span> <span class="nav-text">三、producer 发布消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#写入方式"><span class="nav-number">3.1.</span> <span class="nav-text">写入方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消息路由"><span class="nav-number">3.2.</span> <span class="nav-text">消息路由</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#写入流程"><span class="nav-number">3.3.</span> <span class="nav-text">写入流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#producer-delivery-guarantee"><span class="nav-number">3.4.</span> <span class="nav-text">producer delivery guarantee</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#四、broker-保存消息"><span class="nav-number">4.</span> <span class="nav-text">四、broker 保存消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#存储方式"><span class="nav-number">4.1.</span> <span class="nav-text">存储方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#存储策略"><span class="nav-number">4.2.</span> <span class="nav-text">存储策略</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#topic-创建与删除"><span class="nav-number">4.3.</span> <span class="nav-text">topic 创建与删除</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#创建-topic"><span class="nav-number">4.3.1.</span> <span class="nav-text">创建 topic</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#删除-topic"><span class="nav-number">4.3.2.</span> <span class="nav-text">删除 topic</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#五、kafka-HA"><span class="nav-number">5.</span> <span class="nav-text">五、kafka HA</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#replication"><span class="nav-number">5.1.</span> <span class="nav-text">replication</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#leader-failover"><span class="nav-number">5.2.</span> <span class="nav-text">leader failover</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#broker-failover"><span class="nav-number">5.3.</span> <span class="nav-text">broker failover</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#controller-failover"><span class="nav-number">5.4.</span> <span class="nav-text">controller failover</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#六、consumer-消费消息"><span class="nav-number">6.</span> <span class="nav-text">六、consumer 消费消息</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#consumer-API"><span class="nav-number">6.1.</span> <span class="nav-text">consumer API</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#The-high-level-consumer-API"><span class="nav-number">6.1.1.</span> <span class="nav-text">The high-level consumer API</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#The-SimpleConsumer-API"><span class="nav-number">6.1.2.</span> <span class="nav-text">The SimpleConsumer API</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#consumer-group"><span class="nav-number">6.2.</span> <span class="nav-text">consumer group</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#消费方式"><span class="nav-number">6.3.</span> <span class="nav-text">消费方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#consumer-delivery-guarantee"><span class="nav-number">6.4.</span> <span class="nav-text">consumer delivery guarantee</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#consumer-rebalance"><span class="nav-number">6.5.</span> <span class="nav-text">consumer rebalance</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#七、注意事项"><span class="nav-number">7.</span> <span class="nav-text">七、注意事项</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#producer-无法发送消息的问题"><span class="nav-number">7.1.</span> <span class="nav-text">producer 无法发送消息的问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#八、参考相关文章列表"><span class="nav-number">8.</span> <span class="nav-text">八、参考相关文章列表</span></a></li></ol></div>
            
          </div>
        </section>
      <!--/noindex-->
      

      
    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">辣椒の酱</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/remove.io/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/remove.io/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/remove.io/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/remove.io/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/remove.io/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/remove.io/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/remove.io/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/remove.io/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/remove.io/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/remove.io/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/remove.io/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/remove.io/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/remove.io/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  

  

  

</body>
</html>
